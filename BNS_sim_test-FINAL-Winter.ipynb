{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1364b81",
   "metadata": {},
   "source": [
    "### Mean Distance + Number of Tiles Calculation Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e323597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ligo.skymap.io\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f85f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ligo.skymap.io\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "print('Yes')\n",
    "\n",
    "def get_probabilities(skymap, ra, dec, radius=0.35*u.deg):\n",
    "    \"\"\"\n",
    "    Compute the probabilities covered in a grid of ra, dec with radius\n",
    "    given a healpix skymap\n",
    "\n",
    "    Pass the legal RA and Dec lists to this function\n",
    "\n",
    "    Note: this radius is such that for the default sky grid (nside=128),\n",
    "    fields overlap such that the area of the sky becomes 1.83 * 4pi steradians.\n",
    "    As a result, the sum of probabilities will be 1.83\n",
    "    \"\"\"\n",
    "    # fact : int, optional\n",
    "    # Only used when inclusive=True. The overlapping test will be done at\n",
    "    # the resolution fact*nside. For NESTED ordering, fact must be a power of 2, less than 2**30,\n",
    "    # else it can be any positive integer. Default: 4.\n",
    "    fact = 1\n",
    "    nside_skymap = hp.npix2nside(len(skymap))\n",
    "    tile_area = 1#np.pi * radius.to(u.deg).value ** 2\n",
    "    pixel_area = hp.nside2pixarea(nside_skymap, degrees=True)\n",
    "    probabilities = np.zeros(len(ra))\n",
    "    vertices = hp.ang2vec([ra-0.5, ra-0.5, ra+0.5, ra+0.5], [dec-0.5, dec+0.5, dec+0.5, dec-0.5], lonlat=True)\n",
    "    for i in range(len(ra)):\n",
    "        #print(vertices[i,:])\n",
    "        sel_pix = hp.query_polygon(nside_skymap, vertices[i,:], inclusive=True, fact=fact)\n",
    "        probabilities[i] = np.sum(skymap[sel_pix]) * \\\n",
    "            tile_area / pixel_area / len(sel_pix)\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "\n",
    "def get_top_tiles(probabilities, frac=0.99):\n",
    "    \"\"\"\n",
    "    probabilities may not add up to 1\n",
    "    return indices of tiles that add up to frac of total\n",
    "    \"\"\"\n",
    "    sortorder = np.argsort(probabilities)\n",
    "    p_cum = np.cumsum(probabilities[sortorder]) / np.sum(probabilities)\n",
    "    startind = np.where(p_cum > 1 - frac)[0][0]\n",
    "    top_tiles = sortorder[startind:]\n",
    "    return np.flip(top_tiles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bded675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tiles(probabilities, frac=0.99):\n",
    "    \"\"\"\n",
    "    probabilities may not add up to 1\n",
    "    return indices of tiles that add up to frac of total\n",
    "    \"\"\"\n",
    "    sortorder = np.argsort(probabilities)\n",
    "    p_cum = np.cumsum(probabilities[sortorder]) / np.sum(probabilities)\n",
    "    startind = np.where(p_cum > 1 - frac)[0][0]\n",
    "    top_tiles = sortorder[startind:]\n",
    "    return np.flip(top_tiles)\n",
    "\n",
    "\n",
    "\n",
    "dead2 = [2,17,23,27,28,33,35,39,44,47,49,50,54,55,79,80,86,88,89,90,94,99,\n",
    "        110,111,112,129,130,142,152,154,162,165,167,168,174,179,180,189,191,\n",
    "        213,215,219,224,227,231,232,244,254,267,274,276,280,294,295,\n",
    "        312,313,335,338,340,342,361,363,380,383,385,388,393,395,\n",
    "        409,432,433,437,440,446,449,453,456,492,493,496,497,498,\n",
    "        513,516,522,523,524,539,549,550,552,553,564,565,567,569,572,575,581,582,583,586,591,\n",
    "        603,605,607,610,653,655,659,661,675,676,678,681,689,693,694,\n",
    "        905,914,916,921,923,924,925,927,928,933,942,943,953,954,960,961,963,964,966,984,985,989,\n",
    "        1103,1110,1146,1154,1160,1166,1169,1174,1175,1178,1185,1190,1195,\n",
    "        1205,1207,1212,1220,1221,1224,1235,1236,1240,1243,1253,1257,1270,1272,1273,1282,1288,\n",
    "        1305,1307,1313,1325,1327,1326,1329,1336,1337,1339,1340,1357,1361,1371,1375,1377,1384,1386,\n",
    "        1414,1439,1450,1470,1471,1497]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####  15, 48, 87, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55088a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2 = pd.read_csv('../../new_reduced_galcat.csv')\n",
    "new = pd.read_csv('../../missing_mass.csv')\n",
    "cat2['Dist'] = cat2['DistMpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7392ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('full.csv')\n",
    "\n",
    "names = d1['num'][:]\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    skym = ligo.skymap.io.fits.read_sky_map('farah/allsky/{}.fits'.format(name), distances=True)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    \n",
    "    #print('\\n\\n\\n',name,'\\n\\n\\n')\n",
    "\n",
    "    tiles = pd.read_csv('tiles_GIT_7.csv')\n",
    "    ralist, declist = np.array(tiles['RA_Center'])*u.deg, np.array(tiles['DEC_Center'])*u.deg\n",
    "    probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(probs, 0.99)\n",
    "    print(name,len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2 = pd.read_csv('../../new_reduced_galcat.csv')\n",
    "new = pd.read_csv('../../missing_mass.csv')\n",
    "cat2['Dist'] = cat2['DistMpc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('full.csv')\n",
    "\n",
    "names = d1['num'][0:]\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    skym = ligo.skymap.io.fits.read_sky_map('farah/allsky/{}.fits'.format(name), distances=True)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    \n",
    "    print('\\n\\n\\n##############################',name,'#################################\\n\\n\\n')\n",
    "\n",
    "    tiles = pd.read_csv('tiles_WINTER.csv')\n",
    "    ralist, declist = np.array(tiles['RA_Center']), np.array(tiles['DEC_Center'])\n",
    "    probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(probs, 0.99)\n",
    "    len(tt)\n",
    "\n",
    "    distmu = hp.ud_grade(skym[0][1], 512)\n",
    "    distsigma = hp.ud_grade(skym[0][2], 512)\n",
    "    prob2d = hp.ud_grade(skym[0][0], 512)\n",
    "\n",
    "\n",
    "    radius = 0.35*u.deg\n",
    "    fact = 1\n",
    "    nside_skymap = 512\n",
    "\n",
    "    tile_area = np.pi * radius.to(u.deg).value ** 2\n",
    "    pixel_area = hp.nside2pixarea(nside_skymap, degrees=True)\n",
    "\n",
    "    sigma_m = np.zeros(len(tt))\n",
    "\n",
    "    mpcd = np.arange(0,1001,20)\n",
    "\n",
    "\n",
    "    \n",
    "    sigma_m_empty_nodist = np.zeros(len(tt))\n",
    "    sigma_m_only = np.zeros(len(tt))\n",
    "    \n",
    "    #if len(tt)\n",
    "\n",
    "    for h in range(len(tt)):\n",
    "        ra = ralist[tt[h]]\n",
    "        dec = declist[tt[h]]\n",
    "\n",
    "        #vecs = hp.ang2vec(ra.to(u.deg).value, dec.to(u.deg).value, lonlat=True)\n",
    "\n",
    "        vertices = hp.ang2vec([ra-0.6/np.cos(dec*np.pi/180), ra-0.6/np.cos(dec*np.pi/180), ra+0.6/np.cos(dec*np.pi/180), ra+0.6/np.cos(dec*np.pi/180)], [dec-0.5, dec+0.5, dec+0.5, dec-0.5], lonlat=True)\n",
    "        sel_pix = hp.query_polygon(nside_skymap, vertices, inclusive=True, fact=fact)\n",
    "        \n",
    "        m,s = np.median(distmu[sel_pix]), np.median(distsigma[sel_pix])\n",
    "        \n",
    "        currcat = cat2[np.isin(np.array(cat2.PIX_ID_512), sel_pix)][['Dist','Mstar']]\n",
    "        currcat = currcat[(currcat.Dist>=m-3*s) & (currcat.Dist<=m+3*s)]\n",
    "        \n",
    "        summass = np.sum(currcat['Mstar'])\n",
    "        masses3 = summass * np.sum(prob2d[sel_pix])\n",
    "        sigma_m_only[h] = summass\n",
    "        sigma_m_empty_nodist[h] = masses3\n",
    "        \n",
    "        prob2d[sel_pix] = 0.0\n",
    "        print(h)\n",
    "        \n",
    "    df = pd.DataFrame({'Unfilled2D':sigma_m_empty_nodist,'MassOnly_Distcut':sigma_m_only})\n",
    "    df.to_csv('Orderings-2D-WINTER/Map_{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('full.csv')\n",
    "\n",
    "names = d1['num']\n",
    "\n",
    "for name in names[125:]:\n",
    "    skym = ligo.skymap.io.fits.read_sky_map('farah/allsky/{}.fits'.format(name), distances=True)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    \n",
    "    print('\\n\\n\\n##############################',name,'#################################\\n\\n\\n')\n",
    "\n",
    "    tiles = pd.read_csv('tiles_WINTER.csv')\n",
    "    ralist, declist = np.array(tiles['RA_Center']), np.array(tiles['DEC_Center'])\n",
    "    probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(probs, 0.99)\n",
    "    print(len(tt))\n",
    "\n",
    "    distmu = hp.ud_grade(skym[0][1], 512)\n",
    "    distsigma = hp.ud_grade(skym[0][2], 512)\n",
    "    prob2d = hp.ud_grade(skym[0][0], 512)\n",
    "\n",
    "\n",
    "    radius = 0.35*u.deg\n",
    "    fact = 1\n",
    "    nside_skymap = 512\n",
    "\n",
    "    tile_area = np.pi * radius.to(u.deg).value ** 2\n",
    "    pixel_area = hp.nside2pixarea(nside_skymap, degrees=True)\n",
    "\n",
    "    sigma_m = np.zeros(len(tt))\n",
    "\n",
    "    mpcd = np.arange(0,1001,20)\n",
    "\n",
    "\n",
    "    sigma_m_empty_dist = np.zeros(len(tt))\n",
    "    sigma_m_empty_nodist = np.zeros(len(tt))\n",
    "    sigma_m_nonempty = np.zeros(len(tt))\n",
    "    sigma_m_noprob = np.zeros(len(tt))\n",
    "    sigma_m_noprob_filled = np.zeros(len(tt))\n",
    "    \n",
    "    for h in range(len(tt)):\n",
    "        ra = ralist[tt[h]]\n",
    "        dec = declist[tt[h]]\n",
    "        \n",
    "        vertices = hp.ang2vec([ra-0.6/np.cos(dec*np.pi/180), ra-0.6/np.cos(dec*np.pi/180), ra+0.6/np.cos(dec*np.pi/180), ra+0.6/np.cos(dec*np.pi/180)], [dec-0.5, dec+0.5, dec+0.5, dec-0.5], lonlat=True)\n",
    "        sel_pix = hp.query_polygon(nside_skymap, vertices, inclusive=True, fact=fact)\n",
    "        \n",
    "        masses1 = np.zeros(len(sel_pix))\n",
    "        masses2 = np.zeros(len(sel_pix))\n",
    "        masses3 = np.zeros(len(sel_pix))\n",
    "        masses4 = np.zeros(len(sel_pix))\n",
    "        masses5 = np.zeros(len(sel_pix))\n",
    "\n",
    "        mpcd = np.arange(0,1001,20)\n",
    "\n",
    "        for j in range(len(sel_pix)):\n",
    "            i = sel_pix[j]\n",
    "            currcat = (cat2[cat2.PIX_ID_512 == i][['Dist','Mstar']])\n",
    "\n",
    "            currcat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            indices = np.arange(0,50,1)\n",
    "            filled = []\n",
    "\n",
    "            distfact = 1/distsigma[i] * np.exp( -(mpcd-distmu[i])**2 / (2*distsigma[i]**2) )\n",
    "\n",
    "            for k in range(len(currcat)):\n",
    "                ind = np.argmin(np.abs(new['distcen'] - currcat['Dist'][k]))\n",
    "                filled.append(ind)\n",
    "\n",
    "            unfilled = np.delete(indices, filled)\n",
    "            masses1[j] = prob2d[i]*(np.sum(currcat['Mstar']*distfact[filled]) + np.sum(new['masstofill'][unfilled]*distfact[unfilled] / (new['num_empty_pixels'][unfilled])))\n",
    "\n",
    "            masses2[j] = prob2d[i]*np.sum(currcat['Mstar']*distfact[filled])\n",
    "\n",
    "            masses3[j] = prob2d[i]*np.sum(currcat['Mstar'])\n",
    "            \n",
    "            masses4[j] = np.sum(currcat['Mstar'])\n",
    "            \n",
    "            masses5[j] = masses4[j] + np.sum(new['masstofill'][unfilled] / (new['num_empty_pixels'][unfilled]))\n",
    "\n",
    "        prob2d[sel_pix] = 0.0\n",
    "\n",
    "        sigma_m_empty_dist[h] = np.sum(masses2)\n",
    "        sigma_m_empty_nodist[h] = np.sum(masses3)\n",
    "        sigma_m_nonempty[h] = np.sum(masses1)\n",
    "        sigma_m_noprob[h] = np.sum(masses4)\n",
    "        sigma_m_noprob_filled[h] = np.sum(masses5)\n",
    "        print(h)\n",
    "        \n",
    "    df = pd.DataFrame({'Filled3D':sigma_m_nonempty, 'Unfilled3D':sigma_m_empty_dist, 'Unfilled2D':sigma_m_empty_nodist, 'NoProb':sigma_m_noprob, 'NoProbFilled':sigma_m_noprob_filled})\n",
    "    df.to_csv('Ordering-WINTER/Map_{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ced89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = 0\n",
    "\n",
    "d1 = pd.read_csv('full.csv')\n",
    "ar = []\n",
    "dis = []\n",
    "a1, a2, a3, a4, a5, a6 = [],[],[],[], [],[]\n",
    "ref = pd.read_csv('full2.csv')\n",
    "nobs = 100\n",
    "\n",
    "for n in d1['num'][latest:]:\n",
    "    cs = pd.read_csv('Ordering-WINTER/Map_{}.csv'.format(n))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist, sigma_m_noprob = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D']), np.array(cs['NoProb'])\n",
    "    fs = pd.read_csv('Orderings-2D-WINTER/Map_{}.csv'.format(n))\n",
    "    sigma_2dmp, monly = np.array(fs['Unfilled2D']), np.array(fs['MassOnly_Distcut'])\n",
    "    #sigma_m_empty_nodist = np.array(pd.read_csv('Orderings-2D/Map_{}.csv'.format(n))['Unfilled2D'])\n",
    "    \n",
    "    order_dist = np.flip(np.argsort(sigma_m_empty_dist)[-nobs:])\n",
    "    order_nodist = np.flip(np.argsort(sigma_m_empty_nodist)[-nobs:])\n",
    "    order_all = np.flip(np.argsort(sigma_m_nonempty)[-nobs:])\n",
    "    order_noprob = np.flip(np.argsort(sigma_m_noprob)[-nobs:])\n",
    "    order_2dmp = np.flip(np.argsort(sigma_2dmp)[-nobs:])\n",
    "    order_mdcut = np.flip(np.argsort(monly)[-nobs:])\n",
    "\n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    a1.append(np.cumsum((sigma_m_nonempty)[order_nodist])[-1] / fullsum)\n",
    "    a2.append(np.cumsum((sigma_m_nonempty)[order_dist])[-1] / fullsum)\n",
    "    a3.append(np.cumsum((sigma_m_nonempty)[order_all])[-1] / fullsum)\n",
    "    a4.append(np.cumsum((sigma_m_nonempty)[order_noprob])[-1] / fullsum)\n",
    "    a5.append(np.cumsum((sigma_m_nonempty)[order_2dmp])[-1] / fullsum)\n",
    "    a6.append(np.cumsum((sigma_m_nonempty)[order_mdcut])[-1] / fullsum)\n",
    "    print(n)\n",
    "    #print(k, a3[-1], a1[-1], a2[-1])\n",
    "        \n",
    "    ar.append(0)\n",
    "    \n",
    "    dis.append(0)\n",
    "    \n",
    "d1['DegArea'][latest:] = ref['DegArea']\n",
    "d1['Mean_Dist'][latest:] = ref['Mean_Dist']\n",
    "d1['P_3dcat'][latest:] = a2\n",
    "d1['P_2dcat_dcut'][latest:] = a5\n",
    "d1['P_2dcat'][latest:] = a1\n",
    "d1['P_massfill'][latest:] = a3\n",
    "d1['P_onlymass'][latest:] = a4\n",
    "d1['P_massdcut'][latest:] = a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca381b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = 0\n",
    "\n",
    "d2 = pd.read_csv('full2.csv')\n",
    "ar = []\n",
    "dis = []\n",
    "a1, a2, a3, a4 = [],[],[],[]\n",
    "numtile = []\n",
    "names = []\n",
    "\n",
    "nobs = 100\n",
    "\n",
    "for nam in d2['num'][latest:]:\n",
    "    n = int(nam)\n",
    "    cs = pd.read_csv('Ordering-WINTER/Map_{}.csv'.format(n))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist, sigma_m_noprob = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D']), np.array(cs['NoProb'])\n",
    "\n",
    "    order_dist = np.flip(np.argsort(sigma_m_empty_dist)[-nobs:])\n",
    "    order_nodist = np.flip(np.argsort(sigma_m_empty_nodist)[-nobs:])\n",
    "    order_all = np.flip(np.argsort(sigma_m_nonempty)[-nobs:])\n",
    "    order_noprob = np.flip(np.argsort(sigma_m_noprob)[-nobs:])\n",
    "\n",
    "\n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    a1.append(np.cumsum((sigma_m_nonempty)[order_nodist])[-1] / fullsum)\n",
    "    a2.append(np.cumsum((sigma_m_nonempty)[order_dist])[-1] / fullsum)\n",
    "    a3.append(np.cumsum((sigma_m_nonempty)[order_all])[-1] / fullsum)\n",
    "    a4.append(np.cumsum((sigma_m_nonempty)[order_noprob])[-1] / fullsum)\n",
    "\n",
    "    #print(k, a3[-1], a1[-1], a2[-1])\n",
    "        \n",
    "    if n in [511,559]:\n",
    "        ar.append(0)\n",
    "        dis.append(0)\n",
    "        continue\n",
    "        \n",
    "    skym = ligo.skymap.io.fits.read_sky_map('farah/allsky/{}.fits'.format(n), distances=True)\n",
    "    print(n)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    #probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(skymap, 0.99)\n",
    "    a = len(tt)*hp.nside2pixarea(512)*3282.8\n",
    "    ar.append(a)\n",
    "    \n",
    "    tt = get_top_tiles(skym[0][0])\n",
    "    li = len(tt)\n",
    "    tt = tt[~np.isinf(skym[0][1][tt])]\n",
    "    dist = (np.sum(skym[0][0][tt]*skym[0][1][tt])/np.sum(skym[0][0][tt]))\n",
    "    dis.append(dist)\n",
    "    \n",
    "d1['DegArea'][latest:] = ar\n",
    "d1['Mean_Dist'][latest:] = dis\n",
    "d1['P_3dcat'][latest:] = a1\n",
    "d1['P_2dcat'][latest:] = a2\n",
    "d1['P_massfill'][latest:] = a3\n",
    "d1['P_onlymass'][latest:] = a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65aa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array(ar)\n",
    "dis = np.array(dis)\n",
    "a1 = np.array(a1)\n",
    "a2 = np.array(a2)\n",
    "a3 = np.array(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame()\n",
    "\n",
    "d1['BNS_num'] = names\n",
    "d1['Area99'] = numtile\n",
    "d1['DegArea'] = ar[np.where(ar!=0)]\n",
    "d1['Mean_Dist'] = dis[np.where(ar!=0)]\n",
    "d1['P_3dcat'] = a1[np.where(ar!=0)]\n",
    "d1['P_2dcat'] = a2[np.where(ar!=0)]\n",
    "d1['P_massfill'] = a3[np.where(ar!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1 = pd.read_csv('BNS_full.csv')\n",
    "p2d = []\n",
    "\n",
    "for nam in d1['num'][latest:]:\n",
    "    if np.isnan(nam):\n",
    "        continue\n",
    "    n = int(nam)\n",
    "    file = pd.read_csv('Ordering-WINTER/Map_{}.csv'.format(n))\n",
    "    #print(len(file))\n",
    "    p2 = np.sum(file.Filled3D[:100]) / np.sum(file.Filled3D[:])\n",
    "    p2d.append(p2)\n",
    "p2d    \n",
    "d1['P_2d'] = np.array(p2d)#[np.where(ar!=0)]\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.to_csv('Sept/full-WINTER100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ba14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760f685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594c987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447af773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48678fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5abbe80d",
   "metadata": {},
   "source": [
    "### Contribution from Catalog and Missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6636a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465da2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7606b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 100\n",
    "\n",
    "kl = [33, 40, 55, 77, 88, 111]\n",
    "#sigma_m = sigma_m[:1008]\n",
    "\n",
    "for k in [33]:\n",
    "    cs = pd.read_csv('BNS_GalCat/BNS_{}.csv'.format(k))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D'])\n",
    "\n",
    "    order_dist = np.flip(np.argsort(sigma_m_empty_dist)[-nobs:])\n",
    "    order_nodist = np.flip(np.argsort(sigma_m_empty_nodist)[-nobs:])\n",
    "    order_all = np.flip(np.argsort(sigma_m_nonempty)[-nobs:])\n",
    "\n",
    "\n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    a1 = np.cumsum((sigma_m_nonempty-sigma_m_empty_dist)[order_nodist]) / fullsum\n",
    "    a2 = np.cumsum((sigma_m_nonempty-sigma_m_empty_dist)[order_dist]) / fullsum\n",
    "    a3 = np.cumsum((sigma_m_nonempty-sigma_m_empty_dist)[order_all]) / fullsum\n",
    "    \n",
    "    b1 = np.cumsum((sigma_m_empty_dist)[order_nodist]) / fullsum\n",
    "    b2 = np.cumsum((sigma_m_empty_dist)[order_dist]) / fullsum\n",
    "    b3 = np.cumsum((sigma_m_empty_dist)[order_all]) / fullsum\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(11,8))\n",
    "    plt.plot(a1, color='green', label='sorted by 3D prob, catalog galaxies')\n",
    "    plt.plot(a2, color='orange', label = 'sorted by 2D prob, catalog galaxies')\n",
    "    plt.plot(a3, color='darkorchid', label = 'sorted by 3D prob, mass filled')\n",
    "    plt.plot(b1, color='green', linestyle='--')\n",
    "    plt.plot(b2, color='orange', linestyle='--')\n",
    "    plt.plot(b3, color='darkorchid', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Observation Number')\n",
    "    plt.ylabel('3D prob*galaxy mass (filled+catalog) covered')\n",
    "    plt.title('BNS {}'.format(k))\n",
    "    plt.text(0,0.12, 'Solid - Catalog Galaxies, Dotted - Mass filled')\n",
    "    plt.show()\n",
    "\n",
    "    print(a3[-1]/a1[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a1419",
   "metadata": {},
   "source": [
    "## BNS 559 - Catalog obscured by galactic plane!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = pd.read_csv('tiles_GIT_7.csv')\n",
    "ralist, declist = np.array(tiles['RA_Center'])*u.deg, np.array(tiles['DEC_Center'])*u.deg\n",
    "\n",
    "nside_skymap = 512\n",
    "radius = 0.35*u.deg\n",
    "fact = 1\n",
    "\n",
    "kl = [33, 40, 55, 77, 88, 111]\n",
    "#sigma_m = sigma_m[:1008]\n",
    "\n",
    "for k in [559]:\n",
    "    cs = pd.read_csv('BNS_GalCat/BNS_{}.csv'.format(k))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D'])\n",
    "\n",
    "    skym = ligo.skymap.io.fits.read_sky_map('bns_astro/allsky/{}.fits'.format(k), distances=True)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(probs)\n",
    "    \n",
    "    z1 = np.zeros(12*512**2)\n",
    "    z2 = np.zeros(12*512**2)\n",
    "    \n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    \n",
    "    for h in range(len(tt)):\n",
    "        ra = ralist[tt[h]]\n",
    "        dec = declist[tt[h]]\n",
    "        vecs = hp.ang2vec(ra.to(u.deg).value, dec.to(u.deg).value, lonlat=True)\n",
    "        sel_pix = hp.query_disc(nside_skymap, vecs, radius.to(u.rad).value, inclusive=True, fact=fact)\n",
    "        z1[sel_pix] = (sigma_m_nonempty - sigma_m_empty_dist)[h]/fullsum\n",
    "        z2[sel_pix] = (sigma_m_empty_dist)[h]/fullsum\n",
    "    \n",
    "    hp.mollview(skymap)\n",
    "    plt.title('BNS-{}-Original'.format(k))\n",
    "    plt.show()\n",
    "    hp.mollview(z1)\n",
    "    plt.title('BNS-{}-Filled Mass'.format(k))\n",
    "    plt.show()\n",
    "    hp.mollview(z2)\n",
    "    plt.title('BNS-{}-Cat Mass'.format(k))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6889ae",
   "metadata": {},
   "source": [
    "## BNS 357, 79 - Catalog along same LOS as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = pd.read_csv('tiles_GIT_7.csv')\n",
    "ralist, declist = np.array(tiles['RA_Center'])*u.deg, np.array(tiles['DEC_Center'])*u.deg\n",
    "\n",
    "nside_skymap = 512\n",
    "radius = 0.35*u.deg\n",
    "fact = 1\n",
    "\n",
    "kl = [33, 40, 55, 77, 88, 111]\n",
    "#sigma_m = sigma_m[:1008]\n",
    "\n",
    "for k in [79,357]:\n",
    "    cs = pd.read_csv('BNS_GalCat/BNS_{}.csv'.format(k))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D'])\n",
    "\n",
    "    skym = ligo.skymap.io.fits.read_sky_map('bns_astro/allsky/{}.fits'.format(k), distances=True)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(probs)\n",
    "    \n",
    "    z1 = np.zeros(12*512**2)\n",
    "    z2 = np.zeros(12*512**2)\n",
    "    \n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    \n",
    "    for h in range(len(tt)):\n",
    "        ra = ralist[tt[h]]\n",
    "        dec = declist[tt[h]]\n",
    "        vecs = hp.ang2vec(ra.to(u.deg).value, dec.to(u.deg).value, lonlat=True)\n",
    "        sel_pix = hp.query_disc(nside_skymap, vecs, radius.to(u.rad).value, inclusive=True, fact=fact)\n",
    "        z1[sel_pix] = (sigma_m_nonempty - sigma_m_empty_dist)[h]/fullsum\n",
    "        z2[sel_pix] = (sigma_m_empty_dist)[h]/fullsum\n",
    "    \n",
    "    hp.mollview(skymap)\n",
    "    plt.title('BNS-{}-Original'.format(k))\n",
    "    plt.show()\n",
    "    hp.mollview(z1)\n",
    "    plt.title('BNS-{}-Filled Mass'.format(k))\n",
    "    plt.show()\n",
    "    hp.mollview(z2)\n",
    "    plt.title('BNS-{}-Cat Mass'.format(k))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc72961",
   "metadata": {},
   "source": [
    "## NSBH 931, 1388 - At same location, also galactic plane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = pd.read_csv('tiles_GIT_7.csv')\n",
    "ralist, declist = np.array(tiles['RA_Center'])*u.deg, np.array(tiles['DEC_Center'])*u.deg\n",
    "\n",
    "nside_skymap = 512\n",
    "radius = 0.35*u.deg\n",
    "fact = 1\n",
    "\n",
    "kl = [33, 40, 55, 77, 88, 111]\n",
    "#sigma_m = sigma_m[:1008]\n",
    "\n",
    "for k in [931, 1388, 1368]:\n",
    "    cs = pd.read_csv('BNS_GalCat/NSBH_{}.csv'.format(k))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D'])\n",
    "\n",
    "    skym = ligo.skymap.io.fits.read_sky_map('nsbh_astro/allsky/{}.fits'.format(k), distances=True)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(probs)\n",
    "    \n",
    "    z1 = np.zeros(12*512**2)\n",
    "    z2 = np.zeros(12*512**2)\n",
    "    \n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    \n",
    "    for h in range(len(tt)):\n",
    "        ra = ralist[tt[h]]\n",
    "        dec = declist[tt[h]]\n",
    "        vecs = hp.ang2vec(ra.to(u.deg).value, dec.to(u.deg).value, lonlat=True)\n",
    "        sel_pix = hp.query_disc(nside_skymap, vecs, radius.to(u.rad).value, inclusive=True, fact=fact)\n",
    "        z1[sel_pix] = (sigma_m_nonempty - sigma_m_empty_dist)[h]/fullsum\n",
    "        z2[sel_pix] = (sigma_m_empty_dist)[h]/fullsum\n",
    "    \n",
    "    hp.mollview(skymap)\n",
    "    plt.title('NSBH-{}-Original'.format(k))\n",
    "    plt.show()\n",
    "    hp.mollview(z1)\n",
    "    plt.title('NSBH-{}-Filled Mass'.format(k))\n",
    "    plt.show()\n",
    "    hp.mollview(z2)\n",
    "    plt.title('NSBH-{}-Cat Mass'.format(k))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42231430",
   "metadata": {},
   "source": [
    "### Plots of Coverage by various sorting modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349919e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 100\n",
    "\n",
    "kb = [33, 40, 55, 77, 88, 111, 81, 160, 238, 8, 334, 289]\n",
    "kn = [120, 77, 300, 56, 69, 81, 633, 644, 447, 926, 74]\n",
    "#sigma_m = sigma_m[:1008]\n",
    "\n",
    "kb = [237,560,550,500,727,737,765]\n",
    "kn = [177,971,273,730,876]\n",
    "\n",
    "kn = [631,531,660,797,889,859,849,838]\n",
    "kb = [347,358,415,448,977]\n",
    "\n",
    "kn = [666, 632, 500,387]\n",
    "kb = [1,487]\n",
    "kn = [1005,1013,1014,1016,1021]\n",
    "\n",
    "kn = [1090, 1055, 1040]\n",
    "\n",
    "kb = list([1004,\n",
    "360,\n",
    "734,\n",
    "847,\n",
    "149,\n",
    "225,\n",
    "275,\n",
    "425,\n",
    "925,\n",
    "930,\n",
    "1045,\n",
    "1088\n",
    "])\n",
    "\n",
    "\n",
    "kb = [1064,\n",
    "1069,\n",
    "1071,\n",
    "1075,\n",
    "1077,\n",
    "1079,\n",
    "1084,\n",
    "1085,\n",
    "1088,\n",
    "1089\n",
    "]\n",
    "\n",
    "kn = [1096,\n",
    "1092,\n",
    "1085,\n",
    "1082,\n",
    "1067,\n",
    "1062\n",
    "]\n",
    "\n",
    "kb = [707,\n",
    "714,\n",
    "717,\n",
    "718,\n",
    "721,\n",
    "735,\n",
    "748,\n",
    "757\n",
    "]\n",
    "\n",
    "kn = [562,\n",
    "565,\n",
    "577,\n",
    "582,\n",
    "584,\n",
    "586,\n",
    "588,\n",
    "594\n",
    "]\n",
    "\n",
    "\n",
    "for k in kn:\n",
    "    cs = pd.read_csv('BNS_GalCat/BNS_{}.csv'.format(k))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D'])\n",
    "\n",
    "    order_dist = np.flip(np.argsort(sigma_m_empty_dist)[-nobs:])\n",
    "    order_nodist = np.flip(np.argsort(sigma_m_empty_nodist)[-nobs:])\n",
    "    order_all = np.flip(np.argsort(sigma_m_nonempty)[-nobs:])\n",
    "\n",
    "\n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    a1 = np.cumsum((sigma_m_nonempty)[order_nodist]) / fullsum\n",
    "    a2 = np.cumsum((sigma_m_nonempty)[order_dist]) / fullsum\n",
    "    a3 = np.cumsum((sigma_m_nonempty)[order_all]) / fullsum\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(11,8))\n",
    "    plt.plot(a1, color='green', label='sorted by 3D prob, catalog galaxies')\n",
    "    plt.plot(a2, color='orange', label = 'sorted by 2D prob, catalog galaxies')\n",
    "    plt.plot(a3, color='darkorchid', label = 'sorted by 3D prob, mass filled')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Observation Number')\n",
    "    plt.ylabel('3D prob*galaxy mass (filled+catalog) covered')\n",
    "    #plt.title('BNS {}'.format(k))\n",
    "    #plt.show()\n",
    "\n",
    "    print(k, a3[-1], a1[-1], a2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = 234\n",
    "\n",
    "d1 = pd.read_csv('NSBH_full.csv')\n",
    "ar = []\n",
    "dis = []\n",
    "a1, a2, a3 = [],[],[]\n",
    "\n",
    "nobs = 100\n",
    "\n",
    "for n in d1['NSBH_num'][latest:]:\n",
    "    cs = pd.read_csv('BNS_GalCat/NSBH_{}.csv'.format(n))\n",
    "    sigma_m_nonempty, sigma_m_empty_nodist, sigma_m_empty_dist = np.array(cs['Filled3D']), np.array(cs['Unfilled2D']), np.array(cs['Unfilled3D'])\n",
    "\n",
    "    order_dist = np.flip(np.argsort(sigma_m_empty_dist)[-nobs:])\n",
    "    order_nodist = np.flip(np.argsort(sigma_m_empty_nodist)[-nobs:])\n",
    "    order_all = np.flip(np.argsort(sigma_m_nonempty)[-nobs:])\n",
    "\n",
    "\n",
    "    fullsum = np.sum(sigma_m_nonempty)\n",
    "    a1.append(np.cumsum((sigma_m_nonempty)[order_nodist])[-1] / fullsum)\n",
    "    a2.append(np.cumsum((sigma_m_nonempty)[order_dist])[-1] / fullsum)\n",
    "    a3.append(np.cumsum((sigma_m_nonempty)[order_all])[-1] / fullsum)\n",
    "\n",
    "    #print(k, a3[-1], a1[-1], a2[-1])\n",
    "        \n",
    "    if n in [511,559]:\n",
    "        ar.append(0)\n",
    "        dis.append(0)\n",
    "        continue\n",
    "        \n",
    "    skym = ligo.skymap.io.fits.read_sky_map('nsbh_astro/allsky/{}.fits'.format(n), distances=True)\n",
    "    print(n)\n",
    "    skymap = hp.ud_grade(skym[0][0], 512)\n",
    "    #probs = get_probabilities(skymap, ralist, declist)\n",
    "    tt = get_top_tiles(skymap, 0.99)\n",
    "    a = len(tt)*hp.nside2pixarea(512)*3282.8\n",
    "    ar.append(a)\n",
    "    \n",
    "    tt = get_top_tiles(skym[0][0])\n",
    "    li = len(tt)\n",
    "    tt = tt[~np.isinf(skym[0][1][tt])]\n",
    "    dist = (np.sum(skym[0][0][tt]*skym[0][1][tt])/np.sum(skym[0][0][tt]))\n",
    "    dis.append(dist)\n",
    "    \n",
    "d1['DegArea'][latest:] = ar\n",
    "d1['Mean_Dist'][latest:] = dis\n",
    "d1['P_3dcat'][latest:] = a1\n",
    "d1['P_2dcat'][latest:] = a2\n",
    "d1['P_massfill'][latest:] = a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49880df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(d1['P_massfill'][69:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417546c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1 = pd.read_csv('BNS_full.csv')\n",
    "p2d = []\n",
    "\n",
    "for n in d1['NSBH_num'][latest:]:\n",
    "    file = pd.read_csv('BNS_GalCat/NSBH_{}.csv'.format(n))\n",
    "    #print(len(file))\n",
    "    p2 = np.sum(file.Filled3D[:100]) / np.sum(file.Filled3D[:])\n",
    "    p2d.append(p2)\n",
    "p2d    \n",
    "d1['P_2d'][latest:] = p2d\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1= d1.sort_values('NSBH_num')\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.to_csv('NSBH_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068eeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(d1.P_massfill < d1.P_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f612e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88233d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.to_csv('BNS_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=512\n",
    "12*n**2*hp.nside2pixarea(n)#, arcmin=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b4546",
   "metadata": {},
   "source": [
    "### Next Tasks:\n",
    "\n",
    "1. Find a way to show why missing mass makes such a diference - \n",
    "a. plot skymaps with probabilities from all 3 components\n",
    "b. show breakup of known / missing mass as dashed lines in cumu plot\n",
    "\n",
    "2. look for trends as a function of median distance, 90% area - find out where 3d+missing makes most difference, where it is similar to 3d-g, 2d etc etc\n",
    "a. 100-tile probab as a function of median distance / area\n",
    "b. histograms of 3 probabs in different distance / area bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1910e",
   "metadata": {},
   "source": [
    "### Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d3539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
